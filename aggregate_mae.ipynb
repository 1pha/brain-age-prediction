{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s] %(levelname)s - %(name)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTS = {\n",
    "    \"naive\": \"../resnet256_naive_checkpoints\",\n",
    "    \"augment\": \"../resnet256_augmentation_checkpoints\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #TODO\n",
    "1. Retrieve learning curve for each seeds\n",
    "2. -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS_LIST = {\n",
    "    _type: glob(ROOTS[_type] + \"/*\") for _type in ROOTS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = sorted(glob(RUNS_LIST[\"naive\"][0] + \"/encoder/*.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(idx: int = 0, which: str = \"naive\", paths: list = RUNS_LIST):\n",
    "\n",
    "    \"\"\"\n",
    "    paths:\n",
    "        List of runs containing ROOT/runs\n",
    "    idx:\n",
    "        Specify which run you will return.\n",
    "    \"\"\"\n",
    "    \n",
    "    runs = sorted(glob(paths[which][idx] + \"/encoder/*.pt\"))\n",
    "    return runs\n",
    "\n",
    "def epoch_parser(run_name: str):\n",
    "\n",
    "    \"\"\"\n",
    "    run_name: will look like as follows\n",
    "        ep000_mae57.33.pt\n",
    "        epXXX_maeXX.XX.pt\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        epoch = run_name[2:5]\n",
    "        return int(epoch)\n",
    "\n",
    "    except:\n",
    "        logger.info(f\"Received {run_name} and couldn't parse into EPOCH with a given run name.\")\n",
    "        raise\n",
    "\n",
    "def mae_parser(run_name: str):\n",
    "\n",
    "    \"\"\"\n",
    "    run_name: will look like as follows\n",
    "        ep000_mae57.33.pt\n",
    "        epXXX_maeXX.XX.pt\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        mae = run_name.split(\"mae\")[-1].rstrip(\".pt\")\n",
    "        return float(mae)\n",
    "    except:\n",
    "        logger.info(f\"Received {run_name} and couldn't parse into MAE with a given run name.\")\n",
    "        raise\n",
    "\n",
    "def to_epoch_mae_tuple(path: str):\n",
    "\n",
    "    run_name = path.split(\"/\")[-1]\n",
    "    return epoch_parser(run_name), mae_parser(run_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_results = [{\n",
    "    path.split(\"/\")[-1]: list(map(to_epoch_mae_tuple, get_runs(idx)))\n",
    "} for idx, path in enumerate(RUNS_LIST[\"naive\"])]\n",
    "\n",
    "augment_results = [{\n",
    "    path.split(\"/\")[-1]: list(map(to_epoch_mae_tuple, get_runs(idx, \"augment\")))\n",
    "} for idx, path in enumerate(RUNS_LIST[\"augment\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/naive_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(naive_results, f)\n",
    "with open(\"./data/augment_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(augment_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(naive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49330/264333322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/naive_results.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(\"./data/naive_results.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58f42be4760d443558357e59ed9d9d34a8c50fd6870ceaeaddb214fd01d8c723"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('research': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
